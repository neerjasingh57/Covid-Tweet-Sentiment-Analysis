# -*- coding: utf-8 -*-
"""Deliv 1 Singh.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z8BXT8N7MCjCAnaTAEzCDIZ0hZtDva6H

Using the supplied sample data set for COVID-19 tweets, conduct the following analysis utilizing concepts from today’s workshop:

Download data set and install all packages and modules defined within config.txt document

Remove ‘stop words’ from the strings of text

After removing stop words, print Part-of-Speech tagging

Generate a “Word Cloud” and based on number of occurrences
"""

#pip install -U pip

!pip install pandas configparser spacy wordcloud matplotlib

import os
import pandas as pd
from configparser import ConfigParser
import spacy
from spacy import displacy
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator

import matplotlib.pyplot as plt

from google.colab import files
df = pd.read_csv('covid-extract_covid_tweets_sample.csv')

pd.set_option('display.max_colwidth', 150)
df.head()

!python -m spacy download en_core_web_sm

nlp = spacy.load('en_core_web_sm')

len(df.Full_Text)

#alt solution from connor
#covid_tweets = []

#for doc in nlp.pipe(df['Full_Text'], batch_size=5000, disable = ["tagger", "parser"]):
  #covid_tweets.append([token.text, token.pos_, token.is_stop] for token in doc)

#alt solution
#texts_pos = []
#i = 0
#while i <= 100000:
  #texts = df.Full_Text[i]
  #texts = str(texts)
  #doc = nlp(texts)

  #for token in doc:
    #texts_pos.append([token.text, token.pos_, token.is_stop])
  
  #i = i + 1

#Final Solution part 1
texts_pos = []
for i in range(0, 1511871):
  texts = df.Full_Text[i]
  texts = str(texts)
  doc = nlp(texts, disable = ["parser", "ner"])

  for token in doc:
    texts_pos.append([token.text, token.pos_, token.is_stop])

len(texts_pos)

#Final Solution part 2
texts_pos_df = pd.DataFrame(texts_pos, columns = ("word", "pos", "is_stop"))
texts_pos_df_t = texts_pos_df[texts_pos_df.is_stop != True]
texts_words = texts_pos_df_t.word
texts_words_list = texts_words.to_list()
str1 = ' '.join(str(e) for e in texts_words_list)

#Final Solution part 3
wordcloud = WordCloud(background_color = "white").generate(str1)

plt.imshow(wordcloud, interpolation = 'bilinear')
plt.axis("off")
plt.show()

#texts = df.Full_Text

#alt solution
#texts_pos_pipe = []

#for token in doc in nlp.pipe(texts, disable = ["parser", "ner"]):
  #texts_pos_pipe.append([token.text, token.pos_, token.is_stop])